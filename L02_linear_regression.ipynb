{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FZEco2HK6D57"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a3nCUqopXHwv"
      },
      "outputs": [],
      "source": [
        "RANDOM_SEED = 0xdeadbeef"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jjTkUw7BWulH"
      },
      "source": [
        "# Lab 02: Linear Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gNnZUk36Xz7_"
      },
      "source": [
        "For the first tasks, we will work with synthetic univariate data.\n",
        "We generate $100$ features $x_i \\in [-1, 1]$ as `x` and two different\n",
        "regression targets `y1` and `y2`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ojta777H2ulb"
      },
      "outputs": [],
      "source": [
        "data_rng = np.random.default_rng(RANDOM_SEED)\n",
        "n = 100\n",
        "x = 2 * data_rng.random(n) - 1  # create n points between -1 and 1\n",
        "\n",
        "# setup synthetic y1\n",
        "true_offset = 0.5\n",
        "true_slope = 1.25\n",
        "noise = data_rng.normal(loc=0., scale=0.25, size=(n,))\n",
        "\n",
        "y1 = true_offset + true_slope * x + noise\n",
        "\n",
        "\n",
        "# setup synthetic y2\n",
        "y2  = true_offset + np.sin(np.pi * x) + noise"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ntdpTWzqZqAU"
      },
      "source": [
        "# Task 1: Scatter Plot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JbNJ7WhzbAtm"
      },
      "source": [
        "In the next cell, we show you how you can use `plt.scatter` to create scatter-plots.\n",
        "\n",
        "A scatter plot is a graphical representation that displays individual data points based on two variables, with one variable plotted along the x-axis and the other plotted along the y-axis. It's commonly used to observe and show relationships between two numeric variables.\n",
        "Plot `x` against the target variable `y1`.\n",
        "\n",
        "The simplest way to create a scatter-plot in `matplotlib` is by calling `plt.scatter(x, y)` where `x` is a list or array of x-coordinates and `y` is a list or array of y-coordinates."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KgN-CimVK9vl"
      },
      "outputs": [],
      "source": [
        "# Let us create a scatter-plot of x and y1\n",
        "plt.scatter(x, y1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5njACsM7LOMp"
      },
      "source": [
        "In the next cell, we re-create the same plot but also label the axes, which is generally a good practice.\n",
        "\n",
        "In `matplotlib` it is common to build a plot incrementally by calling many functions (such as `plt.xlabel` and `plt.ylabel` here), before displaying the result using `plt.show()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MxYMdhfxyYAd"
      },
      "outputs": [],
      "source": [
        "plt.scatter(x, y1)\n",
        "plt.xlabel(\"x\")\n",
        "plt.ylabel(\"y1\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFTpeQMrL4mx"
      },
      "source": [
        "## ðŸš¨ Task 1A (1 Point) ðŸš¨\n",
        "\n",
        "Your turn:\n",
        "\n",
        "* create a scatter-plot of `x` and `y2`.\n",
        "* Study the plot: do you think the relationship between `x` and `y2` is linear?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HpzwoBdQDd-d"
      },
      "outputs": [],
      "source": [
        "# TODO\n",
        "plt.scatter(x, y2)\n",
        "plt.xlabel(\"x\")\n",
        "plt.ylabel(\"y2\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VBXqkBMczI1"
      },
      "source": [
        "ðŸ“¢ **<mark>On Moodle</mark>** ðŸ“¢\n",
        "\n",
        "* Report whether the relationship between `x` and `y2` is linear."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m0-7H6eSOL9i"
      },
      "source": [
        "# Answer\n",
        "no it is not linear (looks like a trigonometric function to me)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rbjhdwFceHlL"
      },
      "source": [
        "# Task 2: Univariate Linear Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ucnYGKbmecz_"
      },
      "source": [
        "You will now implement Linear Regression with a single variable. In class you have seen that the underlying model is: $y = \\theta_0 + \\theta_1x$.\n",
        "\n",
        "You also derived the closed formula for $\\theta_0$ and $\\theta_1$:\n",
        "\n",
        "* $\\hat{\\theta}_1 = \\frac{\\sum_{i=1}^{m} (x_i - \\mu(x))(y_i - \\mu(y))}{\\sum_{i=1}^{m}(x_i - \\mu(x))^2}$\n",
        "* $\\hat{\\theta}_0 = \\mu(y) - \\hat{\\theta}_1\\mu(x)$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SlMsQokKdksd"
      },
      "source": [
        "## ðŸš¨ Task 2A (2 Points) ðŸš¨\n",
        "\n",
        "In the following cell, implement the `.fit` and `.predict` methods:\n",
        "* In the `.predict` method you will have to apply the model to the input `x`\n",
        "* In the `.fit` method you will have to compute $\\hat{\\theta}_0$ and $\\hat{\\theta}_1$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qS0Oa5Btgk74"
      },
      "outputs": [],
      "source": [
        "class UnivariateLinearRegression:\n",
        "\n",
        "  def __init__(self):\n",
        "    self.theta_0: float = 0.\n",
        "    self.theta_1: float = 0.\n",
        "\n",
        "  def predict(self, x):\n",
        "    y_pred = self.theta_0 + self.theta_1 * x\n",
        "    return y_pred\n",
        "\n",
        "  def fit(self, x, y):\n",
        "    # TODO\n",
        "    x_mean = np.mean(x)\n",
        "    y_mean = np.mean(y)\n",
        "    self.theta_1 = np.sum((x - x_mean) * (y - y_mean)) / np.sum((x - x_mean) ** 2)\n",
        "    self.theta_0 = y_mean - self.theta_1 * x_mean\n",
        "\n",
        "    return self"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ySKlBT7dd1hS"
      },
      "source": [
        "ðŸ“¢ **<mark>On Moodle</mark>**: ðŸ“¢\n",
        "\n",
        "* Make a snapshot, or copy and submit the code you have written in the cell above."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9LzenH1UhLOs"
      },
      "source": [
        "Now we fit the linear model to `x` and the target `y1`:\n",
        "\n",
        "* Create an instance of the class `UnivariateLinearRegression`\n",
        "* fit the model using its `.fit` method\n",
        "* get the predicted values, using `.predict`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hdIrwBLG1I_8"
      },
      "outputs": [],
      "source": [
        "lin_reg_uni = UnivariateLinearRegression()\n",
        "lin_reg_uni.fit(x, y1)\n",
        "y_pred = lin_reg_uni.predict(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "elE3OfjHjBRO"
      },
      "source": [
        "In the next cell, we provide a helper function to visualize your fitted linear model, based on `x`, the true values of `y` (`y_true`) and the predicted values of `y` (`y_pred`):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T0eKDuRt1YOF"
      },
      "outputs": [],
      "source": [
        "def plot_model(x, y_pred, y_true):\n",
        "  # scatter plot of the true data points\n",
        "  plt.scatter(x, y_true)\n",
        "  # plot the fitted line\n",
        "  plt.plot(x, y_pred, c=\"r\")\n",
        "  # label axes\n",
        "  plt.xlabel(\"x\")\n",
        "  plt.ylabel(\"y\")\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pwxsx5lGOx3O"
      },
      "source": [
        "We use `plot_model` to visualize to outcome of our linear regression for `x` and `y1`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2goCBVKLPBHm"
      },
      "outputs": [],
      "source": [
        "plot_model(x=x, y_pred=y_pred, y_true=y1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tt2RnAwAG1n9"
      },
      "source": [
        "Now we repeat the same steps for `x` and `y2`. Inspect the plot and reflect on your answer to Task 2A."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ccq3GI17Ga2x"
      },
      "outputs": [],
      "source": [
        "lin_reg_uni = UnivariateLinearRegression()\n",
        "lin_reg_uni.fit(x, y2)\n",
        "y_pred = lin_reg_uni.predict(x)\n",
        "\n",
        "plot_model(x, y_pred, y2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ta5zAjsuQFlR"
      },
      "source": [
        "# Task 3: Multivariate Linear Regression using the Normal Equation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgVABRUlWwo6"
      },
      "source": [
        "In the next cell, we provide a function to generate synthetic data for\n",
        "multivariate linear regression."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eEm4eB2GS1gJ"
      },
      "outputs": [],
      "source": [
        "def create_random_data(m: int, n: int, random_seed: int = RANDOM_SEED):\n",
        "  \"\"\"\n",
        "  m: number of samples\n",
        "  n: number of dimensions\n",
        "  random_seed: seed to initialize random number generator\n",
        "  \"\"\"\n",
        "  rng = np.random.default_rng(random_seed)\n",
        "  # random data\n",
        "  X = rng.standard_normal(size=(m, n))\n",
        "  # random true model parameters\n",
        "  theta = rng.standard_normal(n)\n",
        "  # random noise\n",
        "  noise = rng.normal(loc=0., scale=.25, size=m)\n",
        "  # observed y values\n",
        "  y = X @ theta + noise\n",
        "  return X, y\n",
        "\n",
        "# create synthetic dataset with 100 observations and 10 dimensions\n",
        "X, y = create_random_data(100, 10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72ecXwtMXorm"
      },
      "source": [
        "In class you have seen that the underlying model for multivariate linear regression is: $y = X\\theta$. Here $X \\in \\mathbb{R}^{m, n}$, $\\theta \\in \\mathbb{R}^{n}$, and $y \\in \\mathbb{R}^{m}$.\n",
        "\n",
        "We also derived a closed formula for $\\theta$:\n",
        "\n",
        " $\\hat{\\theta} = (X^{T}X)^{-1}X^{T}y$\n",
        "\n",
        "This is known as the *normal equation*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDb5iT2DbCQT"
      },
      "source": [
        "The normal equation can be used to solve univariate and also multivariate linear regression problems, and we have shown that it yields optimal parameters.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8dw4O4zzblU7"
      },
      "source": [
        "In the next cell we implement the normal equation $\\hat{\\theta} = (X^{T}X)^{-1}X^{T}y$ and apply it to our data `X` and `y`.\n",
        "\n",
        "`numpy` reminder:\n",
        "* the transpose of `X` is written `X.T`\n",
        "* matrix multiplication is written with the `@` symbol, e.g. `A @ B`.\n",
        "* you can compute the inverse of a matrix `A` using `np.linalg.inv(A)`. However, it is more numerically stable (and yes, this can really make a difference in practice!) to use a method such as `pinv` or `solve`, as noted below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r6Af3VQ-Tqco"
      },
      "outputs": [],
      "source": [
        "theta = (np.linalg.inv(X.T @ X) @ X.T) @ y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0CvpicyfLi5"
      },
      "source": [
        "*Computing the matrix inverse as part of a larger expression*: when solving the normal equation, we don't actually care about the inverse $(X^{T}X)^{-1}$ by itself; rather, we care about its value <em>when multiplied by another vector</em>. In particular, the expression $(X^{T}X)^{-1}X^{T}$ is also known as the [Moore-Penrose Pseudoinverse](https://en.wikipedia.org/wiki/Moore%E2%80%93Penrose_inverse) of $X$ and can be computed directly using `np.linalg.pinv(X)`, which is generally more efficient. Alternatively, you can solve the normal equation as `np.linalg.solve(X.T @ X, X.T @ y)`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ozPqV-ekc3sX"
      },
      "source": [
        "In the next cell, we provide a helper function to create a residual plot\n",
        "based on the true values of `y` (`y_true`) and the predicted values of `y` (`y_pred`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_hjDkSzedCVc"
      },
      "outputs": [],
      "source": [
        "def residual_plot(y_true, y_pred):\n",
        "  residual = y_pred - y_true\n",
        "  plt.scatter(y_true, residual)\n",
        "  plt.xlabel(\"y\")\n",
        "  plt.ylabel(\"residual\")\n",
        "  plt.title(\"Residual Plot\")\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wPgYF6W2damr"
      },
      "source": [
        "Below we compute the predicted values of `y` based on the value of $\\theta$ you computed using the normal equation. Then we plot the residuals using `residual_plot`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t1r2mDlCdQNs"
      },
      "outputs": [],
      "source": [
        "y_pred = X @ theta\n",
        "\n",
        "residual_plot(y_true=y, y_pred=y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sIQLVzb3gwAR"
      },
      "source": [
        "## Performance of Normal Equation\n",
        "\n",
        "Max Clever has seen the slides for next lecture already â€“ where we will discuss alternative methods such as \"gradient descent\" for linear regression.\n",
        "\n",
        "Now he wonders: *Why do we need other algorithms, when the normal equation solves the problem already?*\n",
        "\n",
        "To answer this question, we will now explore how the runtime of computing the normal equation depends on the input size $n$ and $m$.\n",
        "\n",
        "In the next cell, we provide a skeleton to measure the runtime of computing the normal equation depending on the problem size n*m.\n",
        "\n",
        "## ðŸš¨ Task 3A (2 Point) ðŸš¨\n",
        "* fill in the blanks in the code below\n",
        "* run the code and explore different values for $m$. For which values of $m$ is the running time still below 30min?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-FZizKeAob-n"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "sizes = []\n",
        "times = []\n",
        "n = 1000\n",
        "for m in [10, 50, 100, 200, 250, 500, 1000]:\n",
        "  # TODO create a dataset with m samples and n dimensions, we provide a helper function for this!\n",
        "  X, y = create_random_data(m, n)\n",
        "\n",
        "  start_time = time.monotonic()\n",
        "  # enter the code you want to time here\n",
        "  elapsed = time.monotonic() - start_time\n",
        "\n",
        "  # TODO what is the input size of the problem\n",
        "  problem_size = m * n\n",
        "\n",
        "  sizes.append(problem_size)\n",
        "  times.append(elapsed)\n",
        "\n",
        "plt.scatter(sizes, times)\n",
        "plt.xlabel('Problem-Size')\n",
        "plt.ylabel('Runtime (s)')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zzn9IONOhZvx"
      },
      "source": [
        "ðŸ“¢ **<mark>On Moodle</mark>** ðŸ“¢\n",
        "\n",
        "Answer the following question:\n",
        "\n",
        "* Plot with different problem sizes\n",
        "* Which problem size yields a running time of approximately 30 minutes?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Z2jBU0sRIjy"
      },
      "outputs": [],
      "source": [
        "sizes = []\n",
        "times = []\n",
        "n = 1000\n",
        "for m in [10, 50, 100, 200, 250, 500, 1000]:\n",
        "  # TODO create a dataset with m samples and n dimensions, we provide a helper function for this!\n",
        "  X, y = create_random_data(m, n)\n",
        "\n",
        "  start_time = time.monotonic()\n",
        "  # enter the code you want to time here\n",
        "  theta = np.linalg.solve(X.T @ X, X.T @ y)\n",
        "  elapsed = time.monotonic() - start_time\n",
        "\n",
        "  # TODO what is the input size of the problem\n",
        "  problem_size = m * n\n",
        "\n",
        "  sizes.append(problem_size)\n",
        "  times.append(elapsed)\n",
        "\n",
        "plt.scatter(sizes, times)\n",
        "plt.xlabel('Problem-Size')\n",
        "plt.ylabel('Runtime (s)')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9W0vLwuzRwZT"
      },
      "source": [
        "To figure out what Problem size yields appr. 30 minutes of running time I'll calculate it because I don't want to sit here for 30 minutes and wait for my code to be finished running.\n",
        "\n",
        "$$\\text{Problem Size} = \\frac{\\text{Desired Time (s)}}{\\text{Time per Problem Size (s)}} \\times \\text{Current Problem Size} $$\n",
        "\n",
        "Given that 30 minutes is 1800 seconds, we can use the data collected in the previous cells to estimate the time per problem size and then calculate the desired problem size.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert times to numpy array for easier manipulation\n",
        "times_array = np.array(times)\n",
        "\n",
        "# Calculate the average time per problem size\n",
        "time_per_problem_size = np.mean(times_array / np.array(sizes))\n",
        "\n",
        "# Calculate the desired problem size for 30 minutes (1800 seconds)\n",
        "desired_time = 1800  # 30 minutes in seconds\n",
        "desired_problem_size = desired_time / time_per_problem_size\n",
        "\n",
        "print(f\"Estimated problem size for approximately 30 minutes of running time: {desired_problem_size}\")\n"
      ],
      "metadata": {
        "id": "Y5x75pG9S_Jd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So estimated problem size for ~30 min of running time: 1306097929.845159"
      ],
      "metadata": {
        "id": "VRQ0aHGlTE6w"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cx-di2EypWy6"
      },
      "source": [
        "## ðŸš¨ Task 3B (2 Point) ðŸš¨\n",
        "\n",
        "We now explore the impact of the number of features, $n$, on the running time:\n",
        "\n",
        "* Modify your solution to Task 3A to measure the runtime dependence on the number of features $n$ instead of the number of samples $m$.\n",
        "* What happens if you use large values for $n$, e.g. $n = 100'000$?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cttPLHu6prPH"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "# TODO\n",
        "sizes = []\n",
        "times = []\n",
        "m = 1000\n",
        "for n in [10, 50, 100, 200, 250, 500, 1000, 100000]:\n",
        "    # create a dataset with m samples and n dimensions\n",
        "    X, y = create_random_data(m, n)\n",
        "\n",
        "    start_time = time.monotonic()\n",
        "    theta = np.linalg.pinv(X) @ y\n",
        "    elapsed = time.monotonic() - start_time\n",
        "\n",
        "    # the input size of the problem\n",
        "    problem_size = m * n\n",
        "\n",
        "    sizes.append(problem_size)\n",
        "    times.append(elapsed)\n",
        "\n",
        "plt.scatter(sizes, times)\n",
        "plt.xlabel('Problem-Size')\n",
        "plt.ylabel('Runtime (s)')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cnwQb2JKpwL_"
      },
      "source": [
        "ðŸ“¢ **<mark>On Moodle</mark>** ðŸ“¢\n",
        "\n",
        "Answer the following question:\n",
        "\n",
        "* Upload your plot with a \"very large\" maximal value for $n$."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "WnYVacaCVHHR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I waited over 2 mins for this..."
      ],
      "metadata": {
        "id": "IFH9dZNBVMZF"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eBAW0JCgrCGf"
      },
      "source": [
        "## OPTIONAL QUESTIONS\n",
        "\n",
        "* Do your responses to Tasks 3A and 3B change if you use `np.linalg.pinv(X)`?\n",
        "* Probably your plots for number of samples $m$ and number of features $n$ look very alike. Can you explain why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dgrNtwsPyigH"
      },
      "source": [
        "# Task 4: Multivariate Linear Regression using `scikit-learn`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_sPWegXCg2y1"
      },
      "source": [
        "In this task we will apply linear regression to non-synthetic data.\n",
        "The variable `X` is a `pandas` `Dataframe` containing features and `y` contains\n",
        "the target. Read through the description to get an idea of the different variables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "djGUQ3kVx9ob"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_diabetes\n",
        "\n",
        "data = load_diabetes(as_frame=True)\n",
        "\n",
        "X = data['data']\n",
        "y = data['target']\n",
        "description = data['DESCR']\n",
        "\n",
        "print(description)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "byOVt9t9_2c7"
      },
      "source": [
        "In the next cell, we will fit a linear regression model on this diabetes dataset\n",
        "using the implementation provided by the popular `scikit-learn` library.\n",
        "\n",
        "Their [implementation](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html) is contained in the `sklearn.linear_model.LinearRegression` class. The most important methods of any `sklearn` model are `.fit` and `.predict`. You will see them a lot in future labs.\n",
        "\n",
        "The `.fit(X, y)` method trains the linear regression model and `.predict(X)` return the model's predictions for the data `X`.\n",
        "\n",
        "You can see them in action in the next cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G4AktC189PAc"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "lin_reg = LinearRegression()\n",
        "lin_reg.fit(X, y)\n",
        "y_pred = lin_reg.predict(X)\n",
        "\n",
        "residual_plot(y_true=y, y_pred=y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQUdYHOXpeLd"
      },
      "source": [
        "The numeric entries of the estimated parameter vector $\\theta$ tell us something about the strength and direction of the relationship between the variables in `X` and the target `y`.\n",
        "\n",
        "\n",
        "The estimated parameters $\\theta$ of the linear model can be found in the `.coef_` member variable. The feature names can be found in the `.feature_names_in_` member variable. They are the same as the names of the columns of `X` and should be in the same order."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y8pyPAMwl5c-"
      },
      "source": [
        "In the next code cell, we will plot the entries of $\\theta$ paired with their corresponding feature name. We will also print out the same information."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3J8vO5FemPQw"
      },
      "source": [
        "## ðŸš¨ Task 4A (3 Points) ðŸš¨\n",
        "\n",
        "Study the plot and printed output of the next cell and answer the following questions:\n",
        "\n",
        "* Which are the 3 most influential features?\n",
        "* How do you interpret the sign of the coefficients?\n",
        "* If you had to exclude 1 feature, which one would you select and why?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "odXnubfHqrfc"
      },
      "outputs": [],
      "source": [
        "thetas = lin_reg.coef_\n",
        "feature_names = lin_reg.feature_names_in_\n",
        "\n",
        "plt.bar(feature_names, thetas)\n",
        "plt.xticks(rotation=90)\n",
        "plt.ylabel(\"theta\")\n",
        "plt.show()\n",
        "\n",
        "print()\n",
        "for th, name in zip(thetas, feature_names):\n",
        "  print(f\"{name}\\t{th}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmrnK-EkmgFW"
      },
      "source": [
        "ðŸ“¢ **<mark>On Moodle</mark>** ðŸ“¢\n",
        "\n",
        "* Report your answers to the 3 questions."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}